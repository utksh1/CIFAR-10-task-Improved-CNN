{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CIFAR-10 task: Baseline vs Improved CNN\n",
                "\n",
                "So, I'm working on this CIFAR-10 task where I have to train a CNN on a small subset (10k images). The goal here isn't just to get a high number, but to see how much we can squeeze out of a small dataset using standard tweaks like Batch Norm and some basic augmentation.\n",
                "\n",
                "I'll start with a super basic baseline and then try to beat it with a few modifications."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import torchvision\n",
                "import torchvision.transforms as transforms\n",
                "from torch.utils.data import DataLoader, Subset\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import os\n",
                "\n",
                "torch.manual_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Sorting out the data\n",
                "\n",
                "Since I'm only using 10,000 images, I need to make sure I'm pulling them randomly from the training set. I've written a helper function here to handle both the plain setup and the augmented version for when I try to improve the model for this task."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_dataloaders(subset_size=10000, batch_size=64, use_augmentation=False):\n",
                "    base_transforms = [\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
                "    ]\n",
                "    \n",
                "    if use_augmentation:\n",
                "        train_transform = transforms.Compose([\n",
                "            transforms.RandomHorizontalFlip(),\n",
                "            transforms.RandomCrop(32, padding=4),\n",
                "        ] + base_transforms)\n",
                "    else:\n",
                "        train_transform = transforms.Compose(base_transforms)\n",
                "\n",
                "    test_transform = transforms.Compose(base_transforms)\n",
                "\n",
                "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
                "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
                "\n",
                "    indices = torch.randperm(len(trainset))[:subset_size]\n",
                "    train_subset = Subset(trainset, indices)\n",
                "\n",
                "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
                "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
                "\n",
                "    return train_loader, test_loader"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Putting the model together\n",
                "\n",
                "I'm keeping the architecture pretty standard—3 conv layers followed by a few fully connected ones. I added a `use_batchnorm` flag so it's easier to toggle for different parts of this task."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleCNN(nn.Module):\n",
                "    def __init__(self, use_batchnorm=False):\n",
                "        super(SimpleCNN, self).__init__()\n",
                "        \n",
                "        self.conv_layer = nn.Sequential(\n",
                "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
                "            nn.BatchNorm2d(32) if use_batchnorm else nn.Identity(),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2, 2),\n",
                "            \n",
                "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
                "            nn.BatchNorm2d(64) if use_batchnorm else nn.Identity(),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2, 2),\n",
                "            \n",
                "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
                "            nn.BatchNorm2d(64) if use_batchnorm else nn.Identity(),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2, 2)\n",
                "        )\n",
                "        \n",
                "        self.fc_layer = nn.Sequential(\n",
                "            nn.Linear(64 * 4 * 4, 128),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(128, 10)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.conv_layer(x)\n",
                "        x = x.view(x.size(0), -1)\n",
                "        x = self.fc_layer(x)\n",
                "        return x"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### The boring part: training logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_model(model, train_loader, test_loader, epochs=10):\n",
                "    model.to(device)\n",
                "    criterion = nn.CrossEntropyLoss()\n",
                "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
                "    \n",
                "    history = {'loss': [], 'acc': []}\n",
                "    \n",
                "    for epoch in range(epochs):\n",
                "        model.train()\n",
                "        running_loss = 0.0\n",
                "        for images, labels in train_loader:\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            optimizer.zero_grad()\n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            running_loss += loss.item()\n",
                "        \n",
                "        model.eval()\n",
                "        correct, total = 0, 0\n",
                "        with torch.no_grad():\n",
                "            for images, labels in test_loader:\n",
                "                images, labels = images.to(device), labels.to(device)\n",
                "                outputs = model(images)\n",
                "                _, predicted = torch.max(outputs.data, 1)\n",
                "                total += labels.size(0)\n",
                "                correct += (predicted == labels).sum().item()\n",
                "        \n",
                "        acc = 100 * correct / total\n",
                "        history['loss'].append(running_loss / len(train_loader))\n",
                "        history['acc'].append(acc)\n",
                "        print(f\"Epoch {epoch+1}: loss={history['loss'][-1]:.3f}, acc={acc:.2f}%\")\n",
                "        \n",
                "    return history"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### First run: The Baseline\n",
                "\n",
                "Let's see what happens if we just train a plain CNN with no data augmentation or batch norm. This should give us a decent starting point for the task."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Starting baseline training...\")\n",
                "loader, plotter = get_dataloaders(use_augmentation=False)\n",
                "model_v1 = SimpleCNN(use_batchnorm=False)\n",
                "hist_v1 = train_model(model_v1, loader, plotter)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Second run: Improving the results\n",
                "\n",
                "Now I'm turning on batch norm and adding some random flips/crops to the training data. Hopefully, this helps the model generalize a bit better."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nStarting improved training...\")\n",
                "loader_aug, _ = get_dataloaders(use_augmentation=True)\n",
                "model_v2 = SimpleCNN(use_batchnorm=True)\n",
                "hist_v2 = train_model(model_v2, loader_aug, plotter)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Comparing the results\n",
                "\n",
                "Quick visualization to see if all that extra work was actually worth it for this task."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 4))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(hist_v1['loss'], label='Baseline')\n",
                "plt.plot(hist_v2['loss'], label='Improved')\n",
                "plt.title('Loss')\n",
                "plt.legend()\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(hist_v1['acc'], label='Baseline')\n",
                "plt.plot(hist_v2['acc'], label='Improved')\n",
                "plt.title('Accuracy')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Final thoughts\n",
                "\n",
                "It's pretty cool to see how much of a jump we got just by adding batch norm and some basic augmentation. Usually, when you have such a small training set, the model just overfits and stops learning anything useful. The improved model jumped up by about 7-8%, which is pretty significant for this task.\n",
                "\n",
                "In a real-world setting—say, if you were trying to build a system for a specific niche task like identifying very specific engine parts—you probably wouldn't have a million images. These techniques are basically survival tools for when you're data-starved. Batch norm keeps things stable, and augmentation stops the model from just memorizing the few images it has."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}